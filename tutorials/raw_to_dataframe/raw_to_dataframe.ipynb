{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5290c1a",
   "metadata": {},
   "source": [
    "Created by: Iyare Oseghae | Date: 6/11/2025\n",
    "\n",
    "Last Updated: June 11, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49e20a",
   "metadata": {},
   "source": [
    "The purpose of this code is to simplify and streamline the task of converting NASA Pandora Data from Text file to dataframe and excel spreadsheet format. Pandora data can be found at the Pandonio Global Network Data Portal: https://data.pandonia-global-network.org/. Link to Git Repository with other helpul tools for working with Pandora Data: https://github.com/Iyare-O/Pandora-Unboxed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ac543",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a901b03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fe87d",
   "metadata": {},
   "source": [
    "# Making The Data Usable: Converting from .txt to . xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae6834c",
   "metadata": {},
   "source": [
    "This code block converts the pandora data from txt format to a Pandas dataFrame and saves the dataFrame as a .xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72817d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Month  Day      Time           Column 1:    Column 2: Column 3:  \\\n",
      "0  2025      1    6  18:54:02  20250106T185402.4Z  9137.787528     27.01   \n",
      "1  2025      1    6  19:04:26  20250106T190426.3Z  9137.794749     26.96   \n",
      "2  2025      1    6  19:14:47  20250106T191447.5Z  9137.801938     26.95   \n",
      "3  2025      1    6  19:25:08  20250106T192508.8Z  9137.809130     26.98   \n",
      "4  2025      1    6  19:38:06  20250106T193806.2Z  9137.818127     27.01   \n",
      "\n",
      "  Column 4: Column 5: Column 6:  ...  Column 60  Column 61   Column 62  \\\n",
      "0     51.92    184.09     79.73  ...  3.590e-05  4.389e-06  5.3166e-05   \n",
      "1     52.14    187.13     77.51  ...  3.624e-05  4.389e-06  4.8987e-05   \n",
      "2     52.48    190.12     75.29  ...  3.657e-05  4.389e-06  5.0770e-05   \n",
      "3     52.93    193.07     73.08  ...  3.690e-05  4.389e-06  4.9654e-05   \n",
      "4     53.66    196.70     70.31  ...  3.731e-05  4.389e-06  4.1852e-05   \n",
      "\n",
      "    Column 63 Column 64 Column 65 Column 66   Column 67 Column 68   Column 69  \n",
      "0  1.3234e-06     13.52      3.62      0.56  3.3072e+01      0.56  1.8143e-05  \n",
      "1  1.3188e-06     13.57      3.64      0.56  5.6032e+01      0.56  1.5045e-05  \n",
      "2  1.3096e-06     13.70      3.67      0.56  3.5584e+01      0.56  1.7727e-05  \n",
      "3  1.3084e-06     13.70      3.67      0.56  5.6133e+01      0.56  1.7063e-05  \n",
      "4  1.3132e-06     13.69      3.67      0.56  4.1694e+01      0.56  1.4820e-05  \n",
      "\n",
      "[5 rows x 73 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"Insert_Path/PandoraXXs1_CityST_L2_rnvh3p1-8.txt\" #(NO2)\n",
    "\n",
    "# Read the file\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract column names and descriptions\n",
    "columns = []\n",
    "data_start_idx = 0\n",
    "for i, line in enumerate(lines):\n",
    "    if re.match(r\"^Column \\d+:\", line):\n",
    "        column_name = line.split(\":\")[1].strip()\n",
    "        columns.append(column_name)\n",
    "    elif re.match(r\"^-+$\", line):\n",
    "        data_start_idx = i + 1\n",
    "        break\n",
    "\n",
    "# Extract data lines and split into lists\n",
    "data_lines = lines[data_start_idx:]\n",
    "\n",
    "# find column names in the .txt file\n",
    "columns = [item for item in data_lines if item.startswith(\"Column\")]\n",
    "\n",
    "#remove \"/n from column header names\"\n",
    "columns = [col.strip() for col in columns]\n",
    "\n",
    "# Shorten column names to first 9 characters\n",
    "short_columns = [col[:9] for col in columns]\n",
    "\n",
    "# Define the regular expression pattern for the desired format\n",
    "pattern = r'^(\\d{4})(\\d{2})(\\d{2})T(\\d{2})(\\d{2})(\\d{2})\\.\\dZ'\n",
    "\n",
    "# Extract lines that match the pattern\n",
    "matching_lines = [line for line in data_lines if re.match(pattern, line)]\n",
    "\n",
    "# Extract year, month, day, and time (hhmmss) from the Timestamp column\n",
    "extracted_data = [re.match(pattern, line).groups() if re.match(pattern, line) else (None, None, None, None, None, None) for line in matching_lines]\n",
    "\n",
    "# Split each line into elements and limit to the length of columns\n",
    "split_lines = [line.split()[:len(columns)] for line in matching_lines]\n",
    "\n",
    "# Convert the list of lists into a pandas DataFrame\n",
    "df = pd.DataFrame(split_lines, columns=short_columns[:len(columns)])\n",
    "\n",
    "# Insert new columns for year, month, day, and time (hhmmss)\n",
    "df.insert(0, 'Year', [data[0] for data in extracted_data])\n",
    "df.insert(1, 'Month', [data[1] for data in extracted_data])\n",
    "df.insert(2, 'Day', [data[2] for data in extracted_data])\n",
    "df.insert(3, 'Time', ['{}:{}:{}'.format(data[3], data[4], data[5]) for data in extracted_data])\n",
    "\n",
    "\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "df['Month'] = df['Month'].astype(int)\n",
    "df['Day'] = df['Day'].astype(int)\n",
    "\n",
    "df.to_excel(\"Save_Path/insert_file_name.xlsx\", index=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3dc0c",
   "metadata": {},
   "source": [
    "# Highlight The Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a369cca7",
   "metadata": {},
   "source": [
    "It is not uncommon that Pandora will have some data missing, get ahead of the game and find out which days are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46404cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš« Days with NO DATA available:\n",
      "   MissingDate\n",
      "0   2025-03-07\n",
      "1   2025-03-08\n",
      "2   2025-03-09\n",
      "3   2025-03-10\n",
      "4   2025-03-11\n",
      "5   2025-03-12\n",
      "6   2025-03-13\n",
      "7   2025-04-07\n",
      "8   2025-04-08\n",
      "9   2025-04-09\n",
      "10  2025-04-24\n",
      "11  2025-05-05\n",
      "12  2025-05-06\n",
      "13  2025-05-07\n",
      "14  2025-05-08\n",
      "15  2025-05-09\n",
      "16  2025-05-10\n",
      "17  2025-05-11\n",
      "18  2025-05-12\n",
      "19  2025-05-13\n",
      "20  2025-05-14\n",
      "21  2025-05-15\n",
      "22  2025-05-16\n",
      "23  2025-05-17\n",
      "24  2025-05-18\n",
      "25  2025-05-19\n",
      "26  2025-05-20\n",
      "27  2025-05-21\n",
      " Missing dates exported to: File_Name"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# === Load your preprocessed data (already has Year, Month, Day) ===\n",
    "# If you've already got sa_df from the previous script, you can skip the Excel read\n",
    "file_path = \"Insert_file.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# === Create a proper datetime column ===\n",
    "sa_df['Date'] = pd.to_datetime(sa_df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# === Generate full date range ===\n",
    "min_date = sa_df['Date'].min()\n",
    "max_date = sa_df['Date'].max()\n",
    "all_dates = pd.date_range(start=min_date, end=max_date, freq='D')\n",
    "\n",
    "# === Get all available unique dates from the dataset ===\n",
    "available_dates = pd.to_datetime(sa_df['Date'].unique())\n",
    "\n",
    "# === Find missing dates ===\n",
    "missing_dates = all_dates.difference(available_dates)\n",
    "\n",
    "# === Output missing days ===\n",
    "missing_df = pd.DataFrame({'MissingDate': missing_dates})\n",
    "print(\"Days with NO DATA available:\")\n",
    "print(missing_df)\n",
    "\n",
    "# === Optional: save to Excel ===\n",
    "output_path = \"file_path/missing_dates.xlsx\"\n",
    "missing_df.to_excel(output_path, index=False)\n",
    "print(f\"Missing dates exported to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feffa2a",
   "metadata": {},
   "source": [
    "# Locating you Varibales of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706718c",
   "metadata": {},
   "source": [
    "This code block print a list of the column numbers and their corresponding variable. This code block is very important since it helps us know exatly where to look for your variable(s) of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a32c77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Column 1: UT date and time for measurement center, yyyymmddThhmmssZ (ISO 8601)',\n",
       " 'Column 2: Fractional days since 1-Jan-2000 UT midnight for measurement center',\n",
       " 'Column 3: Effective duration of measurement [s]',\n",
       " 'Column 4: Solar zenith angle for measurement center [deg]',\n",
       " 'Column 5: Solar azimuth for measurement center [deg], 0=north, increases clockwise',\n",
       " 'Column 6: Lunar zenith angle for measurement center [deg]',\n",
       " 'Column 7: Lunar azimuth for measurement center [deg], 0=north, increases clockwise',\n",
       " 'Column 8: Pointing zenith angle for measurement center [deg]',\n",
       " 'Column 9: Pointing azimuth for measurement center [deg], 0=north, increases clockwise',\n",
       " 'Column 10: rms of unweighted fitting residuals, -9=fitting not successful',\n",
       " 'Column 11: Normalized rms of fitting residuals weighted with independent uncertainty, -9=fitting not successful or no uncertainty given',\n",
       " 'Column 12: Expected rms of unweighted fitting residuals based on independent uncertainty, -9=fitting not successful or no uncertainty given',\n",
       " 'Column 13: Expected normalized rms of weighted fitting residuals based on independent uncertainty, -9=fitting not successful or no uncertainty given',\n",
       " 'Column 14: Climatological station pressure [mbar]',\n",
       " 'Column 15: Climatological station temperature [K]',\n",
       " 'Column 16: Climatological effective O2 height [km]',\n",
       " 'Column 17: Climatological effective O2O2 height [km]',\n",
       " 'Column 18: Climatological surface O2 concentration [mol/m3]',\n",
       " 'Column 19: Climatological surface O2O2 concentration [mol2/m6]',\n",
       " 'Column 20: Climatological total O2 column [mol/m2]',\n",
       " 'Column 21: Climatological total O2O2 column [mol2/m5]',\n",
       " 'Column 22: Data processing type index',\n",
       " 'Column 23: Calibration file version',\n",
       " 'Column 24: Calibration file validity starting date',\n",
       " 'Column 25: Mean value of measured data inside fitting window [same units as measurements]',\n",
       " 'Column 26: Wavelength effective temperature [Â°C], 999=no effective temperature given',\n",
       " 'Column 27: Estimated average residual stray light level [%] (only valid for stray light correction methods 2 and higher)',\n",
       " 'Column 28: Retrieved wavelength shift from L1 data [nm], -9=no wavelength change determination',\n",
       " 'Column 29: Retrieved total wavelength shift [nm], -9=no wavelength change fitting',\n",
       " 'Column 30: Retrieved resolution change [%], -999=no resolution change fitting',\n",
       " 'Column 31: Integration time [ms]',\n",
       " 'Column 32: Number of bright count cycles',\n",
       " 'Column 33: Effective position of filterwheel #1, 0=filterwheel not used, 1-9 are valid positions',\n",
       " 'Column 34: Effective position of filterwheel #2, 0=filterwheel not used, 1-9 are valid positions',\n",
       " 'Column 35: Atmospheric variability [%], 999=no atmospheric variability was determined',\n",
       " 'Column 36: L1 data quality flag, 0=assured high quality, 1=assured medium quality, 2=assured low quality, 10=not-assured high quality, 11=not-assured medium quality, 12=not-assured low quality',\n",
       " 'Column 37: Sum over 2^i using those i, for which the corresponding L1 data quality parameter exceeds the DQ1 limit, 0=Saturated data, 1=Too few dark counts measurements, 2=No temperature given or effective temperature too different from the reference temperature, 3=Dark count too high, 4=Unsuccessful dark background fitting, 5=The dark count differs significantly from the dark map for too many pixels, 6=Absolute value of estimated average residual stray light level too high, 7=Although attempted, no wavelength change could be retrieved, 8=Absolute value of retrieved wavelength shift too large, 9=Retrieved wavelength shift differs too much from the shift predicted by the effective temperature',\n",
       " 'Column 38: Sum over 2^i using those i, for which the corresponding L1 data quality parameter exceeds the DQ2 limit (same parameters as for DQ1)',\n",
       " 'Column 39: L2Fit data quality flag, 0=assured high quality, 1=assured medium quality, 2=assured low quality, 10=not-assured high quality, 11=not-assured medium quality, 12=not-assured low quality',\n",
       " 'Column 40: Sum over 2^i using those i, for which the corresponding L2Fit data quality parameter exceeds the DQ1 limit, 0=L1 data quality above 0, 1=Spectral fitting was not successful, 2=Wavelength shift too large, 3=Normalized rms of fitting residuals weighted with independent uncertainty too large',\n",
       " 'Column 41: Sum over 2^i using those i, for which the corresponding L2Fit data quality parameter exceeds the DQ2 limit (same parameters as for DQ1)',\n",
       " 'Column 42: L2 data quality flag for water vapor, 0=assured high quality, 1=assured medium quality, 2=assured low quality, 10=not-assured high quality, 11=not-assured medium quality, 12=not-assured low quality, 20=unusable high quality, 21=unusable medium quality, 22=unusable low quality',\n",
       " 'Column 43: Sum over 2^i using those i, for which the corresponding L2 data quality parameter for water vapor exceeds the DQ1 limit, 0=L2Fit data quality above 0, 1=Retrieval error, 2=Air mass factor too large, 3=Atmospheric variability too large',\n",
       " 'Column 44: Sum over 2^i using those i, for which the corresponding L2 data quality parameter for water vapor exceeds the DQ2 limit (same parameters as for DQ1)',\n",
       " 'Column 45: Water vapor surface concentration [mol/m3], -9e99=retrieval not successful',\n",
       " 'Column 46: Independent uncertainty of water vapor surface concentration [mol/m3], -6=no surface concentration was retrieved since the maximum viewing zenith angle was below 87deg, -7=uncertainty could not be retrieved since slant column uncertainties were missing',\n",
       " 'Column 47: Water vapor surface concentration index, 1=Fully mixed case from extrapolation to horizon, 2=Fully mixed case from largest pointing zenith angle, 3=Heterogeneous case from extrapolation to horizon, 4=Heterogeneous case from largest pointing zenith angle, -6=no surface concentration was retrieved since the maximum viewing zenith angle was below 87deg',\n",
       " 'Column 48: Water vapor heterogeneity flag, 0=well mixed conditions, 1=heterogeneous conditions, -6=no surface concentration was retrieved since the maximum viewing zenith angle was below 87deg',\n",
       " 'Column 49: Water vapor tropospheric vertical column amount [moles per square meter], -9e99=retrieval not successful',\n",
       " 'Column 50: Independent uncertainty of water vapor tropospheric vertical column amount [moles per square meter], -4=tropospheric column was estimated from direct sun measurements using effective temperature, -5=tropospheric column was estimated from direct sun measurements using stratospheric climatology, -7=uncertainty could not be retrieved since slant column uncertainties were missing',\n",
       " 'Column 51: Maximum horizontal distance for water vapor tropospheric column [km]',\n",
       " 'Column 52: Maximum vertical distance for water vapor tropospheric column [km]',\n",
       " 'Column 53: L2 data quality flag for nitrogen dioxide, 0=assured high quality, 1=assured medium quality, 2=assured low quality, 10=not-assured high quality, 11=not-assured medium quality, 12=not-assured low quality, 20=unusable high quality, 21=unusable medium quality, 22=unusable low quality',\n",
       " 'Column 54: Sum over 2^i using those i, for which the corresponding L2 data quality parameter for nitrogen dioxide exceeds the DQ1 limit, 0=L2Fit data quality above 0, 1=Retrieval error, 2=Air mass factor too large, 3=Atmospheric variability too large',\n",
       " 'Column 55: Sum over 2^i using those i, for which the corresponding L2 data quality parameter for nitrogen dioxide exceeds the DQ2 limit (same parameters as for DQ1)',\n",
       " 'Column 56: Nitrogen dioxide surface concentration [mol/m3], -9e99=retrieval not successful',\n",
       " 'Column 57: Independent uncertainty of nitrogen dioxide surface concentration [mol/m3], -6=no surface concentration was retrieved since the maximum viewing zenith angle was below 87deg, -7=uncertainty could not be retrieved since slant column uncertainties were missing',\n",
       " 'Column 58: Nitrogen dioxide surface concentration index, 1=Fully mixed case from extrapolation to horizon, 2=Fully mixed case from largest pointing zenith angle, 3=Heterogeneous case from extrapolation to horizon, 4=Heterogeneous case from largest pointing zenith angle, -6=no surface concentration was retrieved since the maximum viewing zenith angle was below 87deg',\n",
       " 'Column 59: Nitrogen dioxide heterogeneity flag, 0=well mixed conditions, 1=heterogeneous conditions, -6=no surface concentration was retrieved since the maximum viewing zenith angle was below 87deg',\n",
       " 'Column 60: Climatological nitrogen dioxide stratospheric column amount [moles per square meter]',\n",
       " 'Column 61: Uncertainty of climatological nitrogen dioxide stratospheric column amount [moles per square meter]',\n",
       " 'Column 62: Nitrogen dioxide tropospheric vertical column amount [moles per square meter], -9e99=retrieval not successful',\n",
       " 'Column 63: Independent uncertainty of nitrogen dioxide tropospheric vertical column amount [moles per square meter], -4=tropospheric column was estimated from direct sun measurements using effective temperature, -5=tropospheric column was estimated from direct sun measurements using stratospheric climatology, -7=uncertainty could not be retrieved since slant column uncertainties were missing',\n",
       " 'Column 64: Maximum horizontal distance for nitrogen dioxide tropospheric column [km]',\n",
       " 'Column 65: Maximum vertical distance for nitrogen dioxide tropospheric column [km]',\n",
       " 'Column 66: Top height of water vapor layer 1 [km], -6=no profile was retrieved since the maximum viewing zenith angle was below 87deg',\n",
       " 'Column 67: Partial water vapor vertical column amount in layer 1 [moles per square meter], -9e99=retrieval not successful',\n",
       " 'Column 68: Top height of nitrogen dioxide layer 1 [km], -6=no profile was retrieved since the maximum viewing zenith angle was below 87deg',\n",
       " 'Column 69: Partial nitrogen dioxide vertical column amount in layer 1 [moles per square meter], -9e99=retrieval not successful']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4299a",
   "metadata": {},
   "source": [
    "I would suggest to make note the variables of interest once you have located them, see below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d65bb4",
   "metadata": {},
   "source": [
    "Column 56: Nitrogen dioxide surface concentration [mol/m3]\n",
    "    \n",
    "Column 62: Nitrogen dioxide tropospheric vertical column amount [moles per square meter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c1b514",
   "metadata": {},
   "source": [
    "# Next See the \"Filtering and Plotting\" code file to find out how to filter your Pandora data for specific time frames and how to plot the data to your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f198a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
